{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "# https://blog.csdn.net/u013832707/article/details/73608504\n",
    "import sys\n",
    "\n",
    "class ShowProcess():\n",
    "    \"\"\"\n",
    "    显示处理进度的类\n",
    "    调用该类相关函数即可实现处理进度的显示\n",
    "    \"\"\"\n",
    "    i = 0 # 当前的处理进度\n",
    "    max_steps = 0 # 总共需要处理的次数\n",
    "    max_arrow = 50 #进度条的长度\n",
    "    infoDone = 'done'\n",
    "\n",
    "    # 初始化函数，需要知道总共的处理次数\n",
    "    def __init__(self, max_steps, infoDone = 'Done'):\n",
    "        self.max_steps = max_steps\n",
    "        self.i = 0\n",
    "        self.infoDone = infoDone\n",
    "\n",
    "    # 显示函数，根据当前的处理进度i显示进度\n",
    "    # 效果为[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
    "    def show_process(self, i=None):\n",
    "        if i is not None:\n",
    "            self.i = i\n",
    "        else:\n",
    "            self.i += 1\n",
    "        num_arrow = int(self.i * self.max_arrow / self.max_steps) #计算显示多少个'>'\n",
    "        num_line = self.max_arrow - num_arrow #计算显示多少个'-'\n",
    "        percent = self.i * 100.0 / self.max_steps #计算完成进度，格式为xx.xx%\n",
    "        process_bar = '[' + '>' * num_arrow + '-' * num_line + ']'\\\n",
    "                      + '%.2f' % percent + '%' + '\\r' #带输出的字符串，'\\r'表示不换行回到最左边\n",
    "        sys.stdout.write(process_bar) #这两句打印字符到终端\n",
    "        sys.stdout.flush()\n",
    "        if self.i >= self.max_steps:\n",
    "            self.close()\n",
    "\n",
    "    def close(self):\n",
    "        print('')\n",
    "        print(self.infoDone)\n",
    "        self.i = 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 读取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取模型model\n",
    "model_whale = keras.models.load_model('whale-model-2023-6-14.h5')\n",
    "model_ship = keras.models.load_model('ship-model-2023-6-14.h5')\n",
    "# 打印模型概述\n",
    "# model_whale.summary()\n",
    "# model_ship.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_data=pd.read_csv('D:/workshop/2023-6-12/2-test/ship/train/train.csv').image.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
      "Processing Finished\n",
      "(6252, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# source_url='D:/workshop/2023-6-12/2-test/ship-resize32/'\n",
    "# process_bar = ShowProcess(6252, 'Processing Finished')\n",
    "# for i in range(6252):\n",
    "#     i_path=source_url+image_data[i]\n",
    "#     image_data[i]=cv2.resize(cv2.imread(i_path,cv2.IMREAD_GRAYSCALE),(32,32))\n",
    "#     process_bar.show_process()\n",
    "# train_images_staked = np.stack(image_data, axis=0)\n",
    "# print(train_images_staked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmpl8mfx6kz\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmpl8mfx6kz\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship quantization size 274.768 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "# object='ship'\n",
    "# # 将Keras模型转换为TfLite模型\n",
    "# converter_quant = tf.lite.TFLiteConverter.from_keras_model(model_ship)\n",
    "# # set the optimization parameters for TensorFlow Lite conversion\n",
    "# converter_quant.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter_quant.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] \n",
    "# # images=tf.convert_to_tensor(train_images_staked)\n",
    "# images = tf.cast(train_images_staked,tf.float32) / 255.0\n",
    "# mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)\n",
    "# def representative_data_gen():\n",
    "#   for input_value in mnist_ds.take(100):\n",
    "#     yield [input_value]\n",
    "# converter_quant.representative_dataset = representative_data_gen\n",
    "# # convert the model to TensorFlow Lite format with float32 activations and int8 weights\n",
    "# quanitfied_model = converter_quant.convert()\n",
    "# #保存转换后的模型\n",
    "# quanitfied_name = object+\"-model-2023-6-14-quantization.tflite\"\n",
    "# open('./tflite_model/'+quanitfied_name, \"wb\").write(quanitfied_model)\n",
    "# print(object,'quantization size',np.round(os.path.getsize('./tflite_model/'+quanitfied_name)/1000,3),'KB')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 模型转换与量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_transform(model,object):\n",
    "    #训练一个keras模型并转换为tflite格式\n",
    "    #源float模型\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    tflite_name = object+\"-model-2023-6-14.tflite\"\n",
    "    open('./tflite_model/'+tflite_name, \"wb\").write(tflite_model)\n",
    "    print(object,'tflite size',np.round(os.path.getsize('./tflite_model/'+tflite_name)/1000,3),'KB')\n",
    "    \n",
    "def model_quantization(model,object):\n",
    "    # 将Keras模型转换为TfLite模型\n",
    "    converter_quant = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    # set the optimization parameters for TensorFlow Lite conversion\n",
    "    converter_quant.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "    # convert the model to TensorFlow Lite format with float32 activations and int8 weights\n",
    "    quanitfied_model = converter_quant.convert()\n",
    "\n",
    "    #保存转换后的模型\n",
    "    quanitfied_name = object+\"-model-2023-6-14-quantization.tflite\"\n",
    "    open('./tflite_model/'+quanitfied_name, \"wb\").write(quanitfied_model)\n",
    "    print(object,'quantization size',np.round(os.path.getsize('./tflite_model/'+quanitfied_name)/1000,3),'KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmpszrz6edd\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmpszrz6edd\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whale tflite size 4233.356 KB\n"
     ]
    }
   ],
   "source": [
    "model_transform(model_whale,'whale') # whale 转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmp0n0y29zb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmp0n0y29zb\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whale quantization size 1063.208 KB\n"
     ]
    }
   ],
   "source": [
    "model_quantization(model_whale,'whale') # whale 量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmpg_j4oiaf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmpg_j4oiaf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship tflite size 1075.324 KB\n"
     ]
    }
   ],
   "source": [
    "model_transform(model_ship,'ship') # ship 转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmp8b9r_xf1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmp8b9r_xf1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship quantization size 275.56 KB\n"
     ]
    }
   ],
   "source": [
    "model_quantization(model_ship,'ship') # ship 量化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 模型测试"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 原模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.1 whale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取模型model\n",
    "# model_whale = keras.models.load_model('D:/workshop/2023-6-12/5-Version/1-whale/whale-model-2023-6-10.h5')\n",
    "model_whale=keras.models.load_model('whale-model-2023-6-15.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_label_30=list() # 创建空列表，用于存储图像-标签对\n",
    "\n",
    "f=open('test_image_label_6_13.txt','r')\n",
    "for i in f.readlines():\n",
    "    image_label_30.append(i.split('\\n')[0]) # 读取图像-标签对\n",
    "f.close()\n",
    "for i in range(len(image_label_30)):\n",
    "    image_label_30[i]=image_label_30[i].split(' ') # 预处理图像-标签对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(image_name,label):\n",
    "    # 加载测试数据并进行预处理\n",
    "    i_path='./whale64x64/'+image_name\n",
    "    test_data = cv2.resize(cv2.imread(i_path,cv2.IMREAD_GRAYSCALE),(32,32))\n",
    "    # test_data = cv2.imread(i_path,cv2.IMREAD_GRAYSCALE).astype('float32')\n",
    "    test_data=np.expand_dims(test_data, axis=-1)\n",
    "    # 调整输入数据的形状\n",
    "    if len(test_data.shape) == 3:\n",
    "        # 单个图像，形状为(64, 64, 1)\n",
    "        test_data = np.expand_dims(test_data, axis=0)\n",
    "    elif len(test_data.shape) == 4:\n",
    "        # 多个图像，形状为(N, 64, 64, 1)\n",
    "        pass  # 数据已经符合要求\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input shape\")\n",
    "    # 进行预测\n",
    "    predictions = model_whale.predict(test_data, verbose=0)\n",
    "    # 判断结果正误\n",
    "    if(predictions.argmax()==int(label)):\n",
    "        print(image_name,label)\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "ADD_accurate=0\n",
    "process_bar = ShowProcess(len(image_label_30), 'Processing Finished')\n",
    "for i in range(len(image_label_30)):\n",
    "   ADD_accurate+=model_test(image_label_30[i][0],image_label_30[i][1])\n",
    "   # process_bar.show_process()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 正确数: 6142\n",
      "训练集 正确率: 48.14\n"
     ]
    }
   ],
   "source": [
    "print('训练集 正确数:',ADD_accurate)\n",
    "print('训练集 正确率:',np.round(ADD_accurate/len(image_label_30)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.2 ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ship = keras.models.load_model('ship-model-2023-6-14.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(image_name,label):\n",
    "    # 加载测试数据并进行预处理\n",
    "    i_path='./ship/train/images/'+image_name\n",
    "    test_data = cv2.resize(cv2.imread(i_path,cv2.IMREAD_GRAYSCALE),(32,32))\n",
    "    test_data=np.expand_dims(test_data, axis=-1)\n",
    "    # 调整输入数据的形状\n",
    "    if len(test_data.shape) == 3:\n",
    "        # 单个图像，形状为(64, 64, 1)\n",
    "        test_data = np.expand_dims(test_data, axis=0)\n",
    "    elif len(test_data.shape) == 4:\n",
    "        # 多个图像，形状为(N, 64, 64, 1)\n",
    "        pass  # 数据已经符合要求\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input shape\")\n",
    "    # 进行预测\n",
    "    predictions = model_ship.predict(test_data, verbose=0)\n",
    "    # 判断结果正误\n",
    "    if(predictions.argmax()==int(label)):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
      "Processing Finished\n",
      "训练集 正确数: 2986\n",
      "训练集 正确率: 59.68\n"
     ]
    }
   ],
   "source": [
    "image_label_5=list() # 创建空列表，用于存储图像-标签对\n",
    "\n",
    "f=open('ship_train_image_label_6_14.txt','r')\n",
    "for i in f.readlines():\n",
    "    image_label_5.append(i.split('\\n')[0]) # 读取图像-标签对\n",
    "f.close()\n",
    "for i in range(len(image_label_5)):\n",
    "    image_label_5[i]=image_label_5[i].split(' ') # 预处理图像-标签对\n",
    "# 训练集\n",
    "ADD_accurate=0\n",
    "process_bar = ShowProcess(len(image_label_5), 'Processing Finished')\n",
    "for i in range(len(image_label_5)):\n",
    "   ADD_accurate+=model_test(image_label_5[i][0],image_label_5[i][1])\n",
    "   process_bar.show_process()\n",
    "print('训练集 正确数:',ADD_accurate)\n",
    "print('训练集 正确率:',np.round(ADD_accurate/len(image_label_5)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
      "Processing Finished\n",
      "测试集 正确数: 558\n",
      "测试集 正确率: 44.68\n"
     ]
    }
   ],
   "source": [
    "image_label_5=list() # 创建空列表，用于存储图像-标签对\n",
    "\n",
    "f=open('ship_test_image_label_6_14.txt','r')\n",
    "for i in f.readlines():\n",
    "    image_label_5.append(i.split('\\n')[0]) # 读取图像-标签对\n",
    "f.close()\n",
    "for i in range(len(image_label_5)):\n",
    "    image_label_5[i]=image_label_5[i].split(' ') # 预处理图像-标签对\n",
    "# 训练集\n",
    "ADD_accurate=0\n",
    "process_bar = ShowProcess(len(image_label_5), 'Processing Finished')\n",
    "for i in range(len(image_label_5)):\n",
    "   ADD_accurate+=model_test(image_label_5[i][0],image_label_5[i][1])\n",
    "   process_bar.show_process()\n",
    "print('测试集 正确数:',ADD_accurate)\n",
    "print('测试集 正确率:',np.round(ADD_accurate/len(image_label_5)*100,2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 量化模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.1 whale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载TFLite模型\n",
    "interpreter = tf.lite.Interpreter(model_path='./tflite_model/whale-model-2023-6-14-quantization.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# 获取输入和输出张量的索引\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "def model_test(image_name,label):\n",
    "    # 加载测试数据并进行预处理\n",
    "    img_path='./whale64x64/'+image_name\n",
    "    # input_data = cv2.resize(cv2.imread(img_path,cv2.IMREAD_GRAYSCALE),(64,64))\n",
    "    input_data = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE).astype('float32')\n",
    "    test_image=input_data.reshape((1,64,64))\n",
    "    # 设置输入张量的值\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "    # 运行模型\n",
    "    interpreter.invoke()\n",
    "    # 获取输出张量的值\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    # 判断结果正误\n",
    "    if(output_data.argmax()==int(label)):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
      "Processing Finished\n"
     ]
    }
   ],
   "source": [
    "whale_image_label_30=list() # 创建空列表，用于存储图像-标签对\n",
    "\n",
    "f=open('test_image_label_6_13.txt','r')\n",
    "for i in f.readlines():\n",
    "    whale_image_label_30.append(i.split('\\n')[0]) # 读取图像-标签对\n",
    "f.close()\n",
    "for i in range(len(whale_image_label_30)):\n",
    "    whale_image_label_30[i]=whale_image_label_30[i].split(' ') # 预处理图像-标签对\n",
    "# 测试集\n",
    "ADD_accurate=0\n",
    "process_bar = ShowProcess(len(whale_image_label_30), 'Processing Finished')\n",
    "for i in range(len(whale_image_label_30)):\n",
    "   ADD_accurate+=model_test(whale_image_label_30[i][0],whale_image_label_30[i][1])\n",
    "   process_bar.show_process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 正确数: 2651\n",
      "训练集 正确率: 20.78\n"
     ]
    }
   ],
   "source": [
    "print('训练集 正确数:',ADD_accurate)\n",
    "print('训练集 正确率:',np.round(ADD_accurate/len(whale_image_label_30)*100,2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.2 ship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载TFLite模型\n",
    "# interpreter = tf.lite.Interpreter(model_path='./tflite_model/ship-model-2023-6-14-quantization.tflite')\n",
    "interpreter = tf.lite.Interpreter(model_path='D:/workshop/2023-6-12/5-Version/2-ship/model/ship-model-2023-6-14-quantization.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# 获取输入和输出张量的索引\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(image_name,label):\n",
    "    # 加载测试数据并进行预处理\n",
    "    # img_path='./ship/train/images/'+image_name\n",
    "    img_path='./ship-resize32/'+image_name\n",
    "    input_data = cv2.resize(cv2.imread(img_path,cv2.IMREAD_GRAYSCALE),(32,32)).astype('float32')\n",
    "    test_image=input_data.reshape((1,32,32))\n",
    "    # 设置输入张量的值\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "    # 运行模型\n",
    "    interpreter.invoke()\n",
    "    # 获取输出张量的值\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    # 判断结果正误\n",
    "    if(output_data.argmax()==int(label)):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
      "Processing Finished\n",
      "训练集 正确数: 3000\n",
      "训练集 正确率: 59.96\n"
     ]
    }
   ],
   "source": [
    "ship_image_label_5=list() # 创建空列表，用于存储图像-标签对\n",
    "\n",
    "f=open('ship_train_image_label_6_14.txt','r')\n",
    "for i in f.readlines():\n",
    "    ship_image_label_5.append(i.split('\\n')[0]) # 读取图像-标签对\n",
    "f.close()\n",
    "for i in range(len(ship_image_label_5)):\n",
    "    ship_image_label_5[i]=ship_image_label_5[i].split(' ') # 预处理图像-标签对\n",
    "\n",
    "ADD_accurate=0\n",
    "process_bar = ShowProcess(len(ship_image_label_5), 'Processing Finished')\n",
    "for i in range(len(ship_image_label_5)):\n",
    "   ADD_accurate+=model_test(ship_image_label_5[i][0],ship_image_label_5[i][1])\n",
    "   process_bar.show_process()\n",
    "print('训练集 正确数:',ADD_accurate)\n",
    "print('训练集 正确率:',np.round(ADD_accurate/len(ship_image_label_5)*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------]0.40%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
      "Processing Finished\n",
      "测试集 正确数: 551\n",
      "测试集 正确率: 44.12\n"
     ]
    }
   ],
   "source": [
    "ship_image_label_5=list() # 创建空列表，用于存储图像-标签对\n",
    "\n",
    "f=open('ship_test_image_label_6_14.txt','r')\n",
    "for i in f.readlines():\n",
    "    ship_image_label_5.append(i.split('\\n')[0]) # 读取图像-标签对\n",
    "f.close()\n",
    "for i in range(len(ship_image_label_5)):\n",
    "    ship_image_label_5[i]=ship_image_label_5[i].split(' ') # 预处理图像-标签对\n",
    "\n",
    "ADD_accurate=0\n",
    "process_bar = ShowProcess(len(ship_image_label_5), 'Processing Finished')\n",
    "for i in range(len(ship_image_label_5)):\n",
    "   ADD_accurate+=model_test(ship_image_label_5[i][0],ship_image_label_5[i][1])\n",
    "   process_bar.show_process()\n",
    "print('测试集 正确数:',ADD_accurate)\n",
    "print('测试集 正确率:',np.round(ADD_accurate/len(ship_image_label_5)*100,2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割线================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载测试数据并进行预处理\n",
    "i_path='./cropped_train_images/'+image_name\n",
    "test_data = cv2.resize(cv2.imread(i_path,cv2.IMREAD_GRAYSCALE),(64,64))\n",
    "test_data=np.expand_dims(test_data, axis=-1)\n",
    "# 调整输入数据的形状\n",
    "if len(test_data.shape) == 3:\n",
    "    # 单个图像，形状为(64, 64, 1)\n",
    "    test_data = np.expand_dims(test_data, axis=0)\n",
    "elif len(test_data.shape) == 4:\n",
    "    # 多个图像，形状为(N, 64, 64, 1)\n",
    "    pass  # 数据已经符合要求\n",
    "else:\n",
    "    raise ValueError(\"Invalid input shape\")\n",
    "# 进行预测\n",
    "predictions = model.predict(test_data, verbose=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 量化后测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载量化后的TFLite模型\n",
    "interpreter = tf.lite.Interpreter(model_path='whale-model-2023-6-10-quantization.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# 获取输入和输出张量的索引\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# 读取测试数据-10张手写数字图片-预处理\n",
    "num_image=list()\n",
    "for i in range(10):\n",
    "    img_path='handwrite_num/{}.png'.format(i)\n",
    "    num_image.append(cv2.resize(cv2.imread(img_path,cv2.IMREAD_GRAYSCALE),(64,64))/255)\n",
    "input_data = np.array(num_image)\n",
    "\n",
    "for i in range(10):\n",
    "    test_image=input_data[i].reshape((1,227,227,3))\n",
    "    # 设置输入张量的值\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "    # 运行模型\n",
    "    interpreter.invoke()\n",
    "    # 获取输出张量的值\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print('num',i,'预测结果',np.argmax(output_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_label_30=list() # 创建空列表，用于存储图像-标签对\n",
    "\n",
    "f=open('test_image_label_6_13.txt','r')\n",
    "for i in f.readlines():\n",
    "    image_label_30.append(i.split('\\n')[0]) # 读取图像-标签对\n",
    "f.close()\n",
    "for i in range(len(image_label_30)):\n",
    "    image_label_30[i]=image_label_30[i].split(' ') # 预处理图像-标签对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(image_name,label):\n",
    "    # 加载测试数据并进行预处理\n",
    "    i_path='./cropped_train_images/'+image_name\n",
    "    test_data = cv2.resize(cv2.imread(i_path,cv2.IMREAD_GRAYSCALE),(64,64))\n",
    "    test_data=np.expand_dims(test_data, axis=-1)\n",
    "    # 调整输入数据的形状\n",
    "    if len(test_data.shape) == 3:\n",
    "        # 单个图像，形状为(64, 64, 1)\n",
    "        test_data = np.expand_dims(test_data, axis=0)\n",
    "    elif len(test_data.shape) == 4:\n",
    "        # 多个图像，形状为(N, 64, 64, 1)\n",
    "        pass  # 数据已经符合要求\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input shape\")\n",
    "    # 进行预测\n",
    "    predictions = model.predict(test_data, verbose=0)\n",
    "    # 判断结果正误\n",
    "    if(predictions.argmax()==int(label)):\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
      "Processing Finished\n"
     ]
    }
   ],
   "source": [
    "# 测试集\n",
    "ADD_accurate=0\n",
    "process_bar = ShowProcess(len(image_label_30), 'Processing Finished')\n",
    "for i in range(len(image_label_30)):\n",
    "   ADD_accurate+=model_test(image_label_30[i][0],image_label_30[i][1])\n",
    "   process_bar.show_process()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集准确数 6152\n",
      "测试集准确率 0.48\n"
     ]
    }
   ],
   "source": [
    "print('测试集 准确数',ADD_accurate)\n",
    "print('测试集 准确率',np.round(ADD_accurate/len(image_label_30),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_label_30=list() # 创建空列表，用于存储图像-标签对\n",
    "\n",
    "f=open('train_image_label_6_13.txt','r')\n",
    "for i in f.readlines():\n",
    "    image_label_30.append(i.split('\\n')[0]) # 读取图像-标签对\n",
    "f.close()\n",
    "for i in range(len(image_label_30)):\n",
    "    image_label_30[i]=image_label_30[i].split(' ') # 预处理图像-标签对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
      "Processing Finished\n"
     ]
    }
   ],
   "source": [
    "# 训练集 前半\n",
    "ADD_accurate=0\n",
    "process_bar = ShowProcess(int(len(image_label_30)/2), 'Processing Finished')\n",
    "for i in range(int(len(image_label_30)/2)):\n",
    "   ADD_accurate+=model_test(image_label_30[i][0],image_label_30[i][1])\n",
    "   process_bar.show_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集-前半 准确数 10733\n",
      "训练集-前半 准确率 0.56\n"
     ]
    }
   ],
   "source": [
    "print('训练集-前半 准确数',ADD_accurate)\n",
    "print('训练集-前半 准确率',np.round(ADD_accurate/int(len(image_label_30)/2)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
      "Processing Finished\n"
     ]
    }
   ],
   "source": [
    "# 训练集 后半\n",
    "ADD_accurate=0\n",
    "process_bar = ShowProcess(int(len(image_label_30)/2), 'Processing Finished')\n",
    "for i in range(int(len(image_label_30)/2)):\n",
    "   ADD_accurate+=model_test(image_label_30[i+int(len(image_label_30)/2)][0],image_label_30[i+int(len(image_label_30)/2)][1])\n",
    "   process_bar.show_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集-后半 准确数 10708\n",
      "训练集-后半 准确率 0.56\n"
     ]
    }
   ],
   "source": [
    "print('训练集-后半 准确数',ADD_accurate)\n",
    "print('训练集-后半 准确率',np.round(ADD_accurate/int(len(image_label_30)/2)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 准确数 21441\n",
      "训练集 准确率 56.02 %\n"
     ]
    }
   ],
   "source": [
    "print('训练集 准确数',10733+10708)\n",
    "print('训练集 准确率',np.round((10733+10708)/len(image_label_30)*100,2),'%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==========分割线============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['melon_headed_whale' # 已经分出的29个物种\n",
    ",'humpback_whale'\n",
    ",'false_killer_whale'\n",
    ",'bottlenose_dolphin'\n",
    ",'beluga'\n",
    ",'minke_whale'\n",
    ",'fin_whale'\n",
    ",'blue_whale'\n",
    ",'gray_whale'\n",
    ",'southern_right_whale'\n",
    ",'common_dolphin'\n",
    ",'kiler_whale'\n",
    ",'pilot_whale'\n",
    ",'dusky_dolphin'\n",
    ",'killer_whale'\n",
    ",'long_finned_pilot_whale'\n",
    ",'sei_whale'\n",
    ",'spinner_dolphin'\n",
    ",'cuviers_beaked_whale'\n",
    ",'spotted_dolphin'\n",
    ",'globis'\n",
    ",'brydes_whale'\n",
    ",'commersons_dolphin'\n",
    ",'white_sided_dolphin'\n",
    ",'short_finned_pilot_whale'\n",
    ",'rough_toothed_dolphin'\n",
    ",'pantropic_spotted_dolphin'\n",
    ",'pygmy_killer_whale'\n",
    ",'frasiers_dolphin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 93d7d0699a1216.jpg melon_headed_whale\n",
      "1 54b9dba2604930.jpg humpback_whale\n",
      "2 2729fe7ad6245f.jpg false_killer_whale\n",
      "3 6c39c44f811efe.jpg bottlenose_dolphin\n",
      "4 d4135027a5647b.jpg beluga\n",
      "5 67338191a6d07d.jpg minke_whale\n",
      "6 d497600106cae2.jpg fin_whale\n",
      "7 d7f47c7a713f91.jpg blue_whale\n",
      "8 d831c5d3af3342.jpg gray_whale\n",
      "9 eafd6677c18db7.jpg southern_right_whale\n",
      "11 b69fb176f39fa0.jpg kiler_whale\n",
      "12 1707e63f92f03f.jpg pilot_whale\n",
      "13 cdfa1a63ed125a.jpg dusky_dolphin\n",
      "14 a0b9d49c67f664.jpg killer_whale\n",
      "15 6f6108b449daab.jpg long_finned_pilot_whale\n",
      "16 12df50e19a90ab.jpg sei_whale\n",
      "17 9b6e59ff6d2309.jpg spinner_dolphin\n",
      "18 35770005852302.jpg cuviers_beaked_whale\n",
      "19 975914ab797f11.jpg spotted_dolphin\n",
      "20 9443c5069ac1df.jpg globis\n",
      "22 c2a9fdd5401ebb.jpg commersons_dolphin\n",
      "23 19d93b543ff684.jpg white_sided_dolphin\n",
      "24 76592eacf0b914.jpg short_finned_pilot_whale\n",
      "27 b40969974439be.jpg pygmy_killer_whale\n"
     ]
    }
   ],
   "source": [
    "final_list=list()\n",
    "for i in range(29):\n",
    "    f=open('./species-test/{}.txt'.format(name[i]),'r')\n",
    "    for speceis_image in f.readlines():\n",
    "        speceis_image=speceis_image.split('\\n')[0]\n",
    "        if model_test(speceis_image.split('\\n')[0],str(i))==1:\n",
    "            print(i,speceis_image,name[i])\n",
    "            # final_list.append(speceis_image)\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        # else:\n",
    "        #     print('not found in species[{}]'.format(name[i]))\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0938bb32569bed.jpg melon_headed_whale\n",
      "21 7a7d0e488c79c6.jpg humpback_whale\n",
      "25 11bbf6dc02655d.jpg false_killer_whale\n",
      "26 703317a1fca5c7.jpg bottlenose_dolphin\n",
      "28 c37aef077d41d1.jpg beluga\n"
     ]
    }
   ],
   "source": [
    "final_list_plus=[10,21,25,26,28]\n",
    "\n",
    "for i in range(5):\n",
    "    f=open('./species-train/{}.txt'.format(name[final_list_plus[i]]),'r')\n",
    "    for speceis_image in f.readlines():\n",
    "        speceis_image=speceis_image.split('\\n')[0]\n",
    "        if model_test(speceis_image.split('\\n')[0],final_list_plus[i]):\n",
    "            print(final_list_plus[i],speceis_image,name[i])\n",
    "            # final_list_plus[i]=speceis_image\n",
    "            break\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
